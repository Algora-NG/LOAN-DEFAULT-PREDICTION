# -*- coding: utf-8 -*-
"""dummiesfor api.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m-wsJ8NNtTgr3XClFwRaHxH7BCs6ITcc
"""

!pip install category_encoders
import pandas as pd
import numpy as np
import warnings
from statsmodels.stats.outliers_influence import variance_inflation_factor
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
# Importing the dataset
ld = pd.read_csv(r"/content/drive/MyDrive/Loan_default.csv")
ld.head(20)

"""**SECTION 1:
EXPLORATORY DATA ANALYSIS**
"""

# checking the datatypes present in the dataset
ld.info()

"""**Observations: The dataset consist of both numeric and categorical features.**"""

# Checking for empty row or nulls
ld.isnull().sum()

"""**Observation**: The dataset does not have any missing values in it"""

# checking for outliers
ld.columns

# Checking for the data distribution of both the numeric and the categorical data
ld.describe(include = 'all')

"""***EXPLORATORY DATA ANALYSIS THE NUMERICAL COLUMNS***"""

import matplotlib.pyplot as plt
# Checking the data distribution of the numerical data
ld.hist( figsize = (22, 20) )
plt.show()

# check for duplicate
ld.duplicated().sum()

"""**Observation**:"""

# THe numerical features are:
colm = ['Age', 'Income', 'LoanAmount', 'CreditScore',
       'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm',
       'DTIRatio', 'Default']

"""**NOTE**: The assigned variable 'colm' also consist of the **target** column 'Default'"""

ld[colm].plot(
    kind = 'box',
    figsize = (20, 5),
    subplots = True
);

"""**Observation**: The numerical columns does not have any **outliers** in it"""

# Removing unneeded column
ld = ld.drop('LoanID', axis = 1)
ld.head()

# Since we are trying to predict  a loan default status, now we create a counplot to visualize our label
ld["Default"].value_counts()
ld["Default"].value_counts()

import seaborn as sns
plt.figure(figsize=(4,2))
sns.countplot(data = ld,x = 'Default')

""" **Observations**: Only a small part of the target variable consists of people who default on loans, that is, the data is considered **imbalance**"""

cat_features = ['Education', 'EmploymentType', 'MaritalStatus',
       'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner']

Num_features = ['Age','Income','LoanAmount', 'CreditScore', 'MonthsEmployed',
                      'NumCreditLines', 'InterestRate', 'LoanTerm','DTIRatio']

# lets explore the correlation between the continous feature variables
# Checking the correlation between the numerical features
correlation = ld[Num_features].corr()
correlation

# visualizing the correlation using a heatmap
plt.figure(figsize=(10,5))
sns.heatmap(correlation,annot = True,cmap= 'viridis')
plt.show()

"""**Observation:** The**correlation analysis** reveals a strong **relationship** between **age** and **interest rate**, which makes sense. **Age** can influence a person's ability to repay a loan, and higher **interest rates** can increase the likelihood of **default**."""

# Let us explore the relationship between DEFAULT AND LOANAMOUNT. let see if loan amount determines if a person will default or not
plt.figure(figsize=(4,3))
sns.boxplot(data = ld,x='Default',y='LoanAmount')

"""**Observation:** It's clear from our analysis that there's a strong **correlation** between the **LoanAmount** and the likelihood of **default**. As the **LoanAmount** increases, so does the **probability** of default."""

# Let us explore the relationship between DEFAULT AND CREDITSCORE. let see how correlating credit score is, to default
plt.figure(figsize=(4,3))
sns.boxplot(data = ld,x='Default',y='CreditScore')

# the summary statistics for the credit score, grouped by the default
ld.groupby('Default')['CreditScore'].describe()

"""**Observation:** **Credit score** significantly influences **default** likelihood, with higher scores indicating lower risk and vice versa, crucial for lenders in assessing borrower reliability."""

# Let us explore the relationship between DEFAULT AND INCOME.
plt.figure(figsize=(4,3))
sns.boxplot(data = ld,x='Default',y='Income')

#the summary statistics for the income, grouped by the default

ld.groupby('Default')['Income'].describe()

"""**Observation:**  The **correlation** is evident: **higher income** levels **correspond** to **decreased default probability**, highlighting the importance of **income** assessment in risk evaluation for lenders."""

# Let us explore the relationship between DEFAULT AND INTEREST RATE.
plt.figure(figsize=(4,3))
sns.boxplot(data = ld,x='Default',y='InterestRate')

# lets calculate the summary statistics for the interest rate, grouped by the default


ld.groupby('Default')['InterestRate'].describe()

"""**Observation:**  The **relationship** is **stark**: **higher interest** rates correspond to **increased default likelihood**, emphasizing the impact of **interest rates** on borrower repayment capacity and risk assessment for lenders."""

# Let us explore the relationship between DEFAULT AND loan term.
plt.figure(figsize=(4,3))
sns.boxplot(data = ld,x='Default',y='LoanTerm')

#the summary statistics for the Loan term, grouped by the default
ld.groupby('Default')['LoanTerm'].describe()

"""**Observation:**"""

plt.figure(figsize=(4,3))
sns.boxplot(data = ld,x='Default',y='DTIRatio')

# lets calculate the summary statistics for the Loan term, grouped by the default


ld.groupby('Default')['DTIRatio'].describe()

"""**Observation:**"""



"""### ***EXPLORATORY DATA ANALYSIS THE CATEGORICAL COLUMNS***

**RATIO OF DEFAULT IN EMPLOYMENT TYPE**
"""

plt.figure(figsize=(7,3))
sns.countplot(data = ld,x = 'EmploymentType', hue = 'Default')

"""**Observation:**"""

yes_default = ld[ld['Default']==1].groupby('EmploymentType').count()['Default']
no_default = ld[ld['Default']==0].groupby('EmploymentType').count()['Default']
percentage_default= yes_default / (yes_default+no_default)
percentage_default

plt.figure(figsize=(6,3))
percentage_default .plot(kind = 'bar')

"""**Observation:** It's evident that unemployed individuals might struggle to repay their loans. This makes sense, as lacking a job typically means lacking a steady income to cover loan payments."""



"""**RATIO OF DEFAULT IN HASMORTGAGE**"""

plt.figure(figsize=(4,3))
sns.countplot(data = ld,x = 'HasMortgage', hue = 'Default')

HasMortgage_yes_default = ld[ld['Default']==1].groupby('HasMortgage').count()['Default']
HasMortgage_no_default = ld[ld['Default']==0].groupby('HasMortgage').count()['Default']
percentage_mortage_default= HasMortgage_yes_default/ (HasMortgage_yes_default+HasMortgage_no_default)
percentage_mortage_default

plt.figure(figsize=(4,3))
percentage_mortage_default.plot(kind = 'bar')

"""**Observation:*"""



"""**RATIO OF DEFAULT IN MARITAL STATUS**"""

plt.figure(figsize=(5,4))
sns.countplot(data = ld,x = 'MaritalStatus', hue = 'Default')

marital_status_yes_default = ld[ld['Default']==1].groupby('MaritalStatus').count()['Default']
marital_status_no_default = ld[ld['Default']==0].groupby('MaritalStatus').count()['Default']
percentage_marital_status_default= (marital_status_yes_default/ (marital_status_yes_default+marital_status_no_default))*100
percentage_marital_status_default

plt.figure(figsize=(5,4))
percentage_marital_status_default.plot(kind = 'bar')

"""**Observation:**"""



"""**RATIO OF DEFAULT IN LOANPURPOSE**"""

loan_purpose_order = sorted(ld['LoanPurpose'].unique())
plt.figure(figsize=(6,4))
sns.countplot(data = ld,x = 'LoanPurpose', hue = 'Default',
              order = loan_purpose_order)

LoanPurpose_yes_default = ld[ld['Default']==1].groupby('LoanPurpose').count()['Default']
LoanPurpose_no_default = ld[ld['Default']==0].groupby('LoanPurpose').count()['Default']
percentage_LoanPurpose_default= (LoanPurpose_yes_default/ (LoanPurpose_yes_default+LoanPurpose_no_default))*100
percentage_LoanPurpose_default

plt.figure(figsize=(5,4))
percentage_LoanPurpose_default.plot(kind = 'bar')

"""**Observation:**"""



"""**RATIO OF DEFAULT IN EDUCATION**"""

plt.figure(figsize=(6,4))
sns.countplot(data = ld,x = 'Education', hue = 'Default')

Education_yes_default = ld[ld['Default']==1].groupby('Education').count()['Default']
Education_no_default = ld[ld['Default']==0].groupby('Education').count()['Default']
percentage_education_default= (Education_yes_default/ (Education_yes_default+Education_no_default))*100
percentage_education_default

plt.figure(figsize=(5,4))
percentage_education_default.plot(kind = 'bar')



"""**RATIO OF DEFAULT IN HASCOSIGNER**"""

plt.figure(figsize=(4,3))
sns.countplot(data = ld,x = 'HasCoSigner', hue = 'Default')

HasCoSigner_yes_default = ld[ld['Default']==1].groupby('HasCoSigner').count()['Default']
HasCoSigner_no_default = ld[ld['Default']==0].groupby('HasCoSigner').count()['Default']
percentage_HasCoSigner_default= (HasCoSigner_yes_default/ (HasCoSigner_yes_default+HasCoSigner_no_default))*100
percentage_HasCoSigner_default

plt.figure(figsize=(4,3))
percentage_HasCoSigner_default.plot(kind = 'bar')



"""**RATIO OF DEFAULT IN HASDEPENDENTS**"""

plt.figure(figsize=(4,3))
sns.countplot(data = ld,x = 'HasDependents', hue = 'Default')

HasDependents_yes_default = ld[ld['Default']==1].groupby('HasDependents').count()['Default']
HasDependents_no_default = ld[ld['Default']==0].groupby('HasDependents').count()['Default']
percentage_HasDependents_default= (HasDependents_yes_default/ (HasDependents_yes_default+HasDependents_no_default))*100
percentage_HasDependents_default

plt.figure(figsize=(4,3))
percentage_HasDependents_default.plot(kind = 'bar')



"""## **STEP 2:**
###    **DATA PREPROCESSING**

Encoding the categorical features using the **"pd.get_dummies"**
"""

ld_encoded = pd.get_dummies(ld[cat_features], drop_first=True, dtype=int)
ld_encoded

ld = pd.concat([ld.drop(['Education','EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents',
                         'LoanPurpose', 'HasCoSigner'],axis = 1),ld_encoded],axis = 1)
ld.head()

X = ld.drop('Default', axis=1)
y = ld['Default']

from sklearn.model_selection import train_test_split

# Splitting data into train, validation and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, shuffle=True)
X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, shuffle=True)

print(X_val.shape)
print(X_test.shape)
print(X_train.shape)

from sklearn.preprocessing import MinMaxScaler

# Feature Scaling (Standardization) my numeric features
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train[Num_features])
X_train_s = pd.DataFrame(X_train_scaled, columns = Num_features)
X_train_s.reset_index(inplace = True)


# Scaling the numeric features in the validation set
X_val_scaled = scaler.transform(X_val[Num_features])
X_val_s = pd.DataFrame(X_val_scaled, columns=Num_features)


# Scaling the numeric features in the test set
X_test_scaled = scaler.transform(X_test[Num_features])
X_test_s = pd.DataFrame(X_test_scaled, columns = Num_features)
X_test_s.reset_index(inplace = True)


print(X_val_s.shape)
print(X_test_s.shape)
print(X_train_s.shape)

# Concatenating the scaled numeric features with the remaining features
X_train.reset_index(inplace = True)
X_val.reset_index(inplace = True)
X_test.reset_index(inplace = True)

X_train = pd.concat([X_train_s, X_train.drop(Num_features, axis=1)], axis=1)
X_val = pd.concat([X_val_s, X_val.drop(Num_features, axis=1)], axis=1)
X_test = pd.concat([X_test_s, X_test.drop(Num_features, axis=1)], axis=1)

print(X_val.shape)
print(X_test.shape)
print(X_train.shape)

X_train

X_train = X_train.drop('index', axis =1)
X_test = X_test.drop('index', axis =1)
X_val = X_val.drop('index', axis =1)



from imblearn.under_sampling import TomekLinks,NearMiss
from imblearn.over_sampling import RandomOverSampler,SMOTE
from imblearn.combine import SMOTETomek


def sampler_function(data_x, data_y, sampler = 0,random_state = 42):
    if sampler == 0:
        sampler = RandomOverSampler(random_state = random_state)
    elif sampler == 1:
        sampler = TomekLinks()
    elif sampler == 2:
        sampler = SMOTE()
    elif sampler == 3:
        sampler = SMOTETomek()
    else:
        sampler = NearMiss()
    X_transformed, y_transformed = sampler.fit_resample(data_x, data_y)

    print('Original dataset shape:', data_y.shape)
    print('Resampled dataset shape:', y_transformed.shape)

    return X_transformed, y_transformed

X1, y1 = sampler_function(X_train, y_train, sampler = 2)

col_name = X1.columns

"""### GAUSSIAN NAIVE BAYES"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB(var_smoothing = 1e-09)

gnb.fit(X1, y1)

gnb_pred = gnb.predict_proba(X_val)[:, 1]

from sklearn.metrics import roc_auc_score
# Deriving the ROC_AUC score
auc_score = roc_auc_score(y_val, gnb_pred)

print(f"AUC-ROC Score: {auc_score}")

threshold = 0.5
gnb_pred_c = (gnb_pred >= threshold).astype(int)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, gnb_pred_c)

cm = confusion_matrix(y_val, gnb_pred_c)
cm = cm.reshape((2, 2))

# Create heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Gaussian Nave Bayes Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_val, gnb_pred_c))





"""### BAGGING CLASSIFIER"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier

base_estimator = DecisionTreeClassifier()
# Initialize the Bagging Classifier
bg = BaggingClassifier(estimator=base_estimator, max_features = 0.5, max_samples = 1.0, n_estimators = 100, random_state=42)

# Train the model
bg.fit(X1, y1)

bg_pred = bg.predict_proba(X_val)[:, 1]

auc_score = roc_auc_score(y_val, bg_pred)

print(f"AUC-ROC Score: {auc_score}")

threshold = 0.5
bg_pred_c = (bg_pred >= threshold).astype(int)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, bg_pred_c)

cm = confusion_matrix(y_val, bg_pred_c)
cm = cm.reshape((2, 2))

# Create heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Bagging classifier Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_val, bg_pred_c))



"""**GRADIENTBOOSTING CLASSIFIER**"""

from sklearn.ensemble import GradientBoostingClassifier
gbc = GradientBoostingClassifier()

gbc.fit(X1, y1)

gbc_pred = gbc.predict_proba(X_val)[:, 1]

auc_score = roc_auc_score(y_val, gbc_pred)

print(f"AUC-ROC Score: {auc_score}")

threshold = 0.5
gbc_pred_c = (gbc_pred >= threshold).astype(int)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, gbc_pred_c)

cm = confusion_matrix(y_val, gbc_pred_c)
cm = cm.reshape((2, 2))

# Create heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Gradient Boosting Classifier Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_val, gbc_pred_c))



"""### RANDOM FOREST CLASSIFIER"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()

rfc.fit(X1, y1)

rfc_pred = rfc.predict_proba(X_val)[:, 1]

auc_score = roc_auc_score(y_val, rfc_pred)

print(f"AUC-ROC Score: {auc_score}")

threshold = 0.5
rfc_pred_c = (rfc_pred >= threshold).astype(int)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, rfc_pred_c)

cm = confusion_matrix(y_val, rfc_pred_c)
cm = cm.reshape((2, 2))

# Create heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Random Forest Classifier Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_val, rfc_pred_c))





"""#### KNN CLASSIFIER"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()

knn.fit(X1, y1)

knn_pred = knn.predict_proba(X_val)[:, 1]

auc_score = roc_auc_score(y_val, knn_pred)

print(f"AUC-ROC Score: {auc_score}")

threshold = 0.5
knn_pred_c = (knn_pred >= threshold).astype(int)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, bg_pred_c)

cm = confusion_matrix(y_val, bg_pred_c)
cm = cm.reshape((2, 2))

# Create heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('KNeighborsClassifier Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_val, knn_pred_c))



"""**TENSORFLOW**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

tsf = Sequential()
tsf.add(Dense(64, input_dim=X1.shape[1], activation='relu'))
tsf.add(Dropout(0.3))
tsf.add(Dense(32, activation='relu'))
tsf.add(Dropout(0.3))
tsf.add(Dense(16, activation='relu'))
tsf.add(Dropout(0.3))
tsf.add(Dense(1, activation='sigmoid'))

# Compile the model
initial_learning_rate = 0.001
tsf.compile(optimizer=Adam(learning_rate = initial_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience= 2)
tsf.fit(X1, y1, epochs=10, batch_size=256, validation_data = [X_val, y_val ], callbacks=[early_stopping])

mtr = pd.DataFrame(tsf.history.history)
mtr

mtr[['loss', 'val_loss']].plot()

mtr[['accuracy', 'val_accuracy']].plot()

#Evaluate the model
loss, accuracy = tsf.evaluate(X_val, y_val)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

# Make predictions and evaluate
tsf_pred = (tsf.predict(X_val) > 0.4).astype("int32")

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, tsf_pred)

cm = confusion_matrix(y_val, tsf_pred)
cm = cm.reshape((2, 2))

# Create heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Tensorflow Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_val, tsf_pred))



"""## **XGBOOST CLASSIFIER**"""

import xgboost as xgb

xgbc = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)

xgbc = xgb.XGBClassifier (colsample_bytree = 0.6, gamma = 0.1, learning_rate = 0.3, n_estimators = 150, reg_alpha = 0, reg_lambda = 1, subsample = 0.8)

xgbc.fit(X1, y1)

xgbc_pred = xgbc.predict_proba(X_val)[:, 1]

from sklearn.metrics import roc_auc_score
auc_score = roc_auc_score(y_val, xgbc_pred)

print(f"AUC-ROC Score: {auc_score}")

threshold = 0.5
xgbc_pred_c = (xgbc_pred >= threshold).astype(int)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, xgbc_pred_c)

cm = confusion_matrix(y_val, xgbc_pred_c)
cm = cm.reshape((2, 2))

# Create heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('XGBOOST classifier Confusion Matrix')
plt.show()



"""## **STACKING CLASSIFIER**"""

from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

# Define base models
base_learners = [
    ('lr', LogisticRegression()),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),
    ('knn', KNeighborsClassifier())
]


meta_learner = LogisticRegression()

# Creating a Stacking Classifier
stack = StackingClassifier(estimators=base_learners, final_estimator=meta_learner)

# Fit the model
stack.fit(X1, y1)

stack_pred = stack.predict_proba(X_val)[:, 1]

from sklearn.metrics import roc_auc_score
auc_score = roc_auc_score(y_val, stack_pred)

print(f"AUC-ROC Score: {auc_score}")

threshold = 0.5
stack_pred_c = (stack_pred >= threshold).astype(int)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, stack_pred_c)

cm = confusion_matrix(y_val, stack_pred_c)
cm = cm.reshape((2, 2))

# Create heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('STACKING Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_val, stack_pred_c))





"""### LINEAR MODELS
#### LOGISTIC REGRESSION
"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(C = 0.1, max_iter = 100, penalty = 'l1', solver = 'saga')



lr.fit(X1, y1)

lr_pred = lr.predict_proba(X_val)[:, 1]

from sklearn.metrics import roc_auc_score
auc_score = roc_auc_score(y_val, lr_pred)

print(f"AUC-ROC Score: {auc_score}")

threshold = 0.5
lr_pred_c = (lr_pred >= threshold).astype(int)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_val, lr_pred_c)

cm = confusion_matrix(y_val, lr_pred_c)
cm = cm.reshape((2, 2))

# Create heatmap
plt.figure(figsize=(5, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title(' LOGISTICREGRESSION Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_val, lr_pred_c))





from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

models = [lr, stack, xgbc, knn, rfc, gbc, bg, gnb]
results_list = []

for model in models:
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results_list.append({
        'Model': model,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1': f1
    })

results_df = pd.DataFrame(results_list)
results_df



"""### Model Result Observations

Upon evaluating the performance of several models for predicting loan defaults, the following observations were made:

- **Logistic Regression**:
  - Exhibited a moderate accuracy of 68.7%, with precision at 22.1% and recall at 67.9%, resulting in an F1 score of 33.3%. This indicates a good recall rate, meaning it can identify many actual defaulters, but also a higher rate of false positives due to its lower precision.

- **Stacking Classifier**:
  - Achieved high accuracy of 86.1%, but precision and recall were relatively low at 25.4% and 10.9%, respectively, leading to an F1 score of 15.3%. This model may benefit from further tuning or more diverse base models.

- **XGBoost Classifier**:
  - Showed high accuracy of 88.5%, with precision at 50.5% but low recall at 10.7%, resulting in an F1 score of 17.6%. Despite its high accuracy, the low recall suggests it misses many actual defaulters.

- **K-Nearest Neighbors (KNN)**:
  - Had an accuracy of 64.1%, precision of 15.7%, and recall of 48.4%, resulting in an F1 score of 23.7%. KNN struggled more with distinguishing between defaulters and non-defaulters, making it less reliable for this dataset.

- **Random Forest Classifier**:
  - Presented a high accuracy of 85.7%, but its precision was 31.0% and recall was 19.6%, resulting in an F1 score of 24.1%. Despite its high accuracy, the low recall suggested it might be overfitting the training data and not generalizing well to new data.

- **Gradient Boost Classfier**:
  - Had an accuracy of 87.6% and a precision of 39.6%, but its recall was very low at 14.4%, with an F1 score of 21.1%. This model could identify defaulters with high precision but missed many actual defaulters, reducing its practical reliability.

- **Bagging**:
  - Showed high accuracy of 88.5%, but the precision of 80.0% and extremely low recall of 0.2% resulted in an F1 score of 0.4%. This configuration is not practical for identifying defaulters effectively.

- **Gaussian Naive Bayes**:
  - Displayed balanced performance, with an accuracy of 69.9%, precision of 21.9%, and recall of 62.9%, resulting in an F1 score of 32.5%. It performed similarly to Logistic Regression, maintaining a reasonable balance between precision and recall, though it still produced a notable number of false positives.

### Summary

Models like the Decision Tree Classifier and Regressor showed high accuracy but struggled with precision and recall, indicating potential overfitting and poor generalization to new data. Logistic Regression and Gaussian Naive Bayes provided more balanced performance metrics, making them potentially more reliable for predicting loan defaults. The results highlight the importance of considering both precision and recall alongside accuracy, as a model with balanced precision and recall offers a better trade-off between false positives and negatives compared to one that excels only in accuracy.

Among all the models evaluated, **Logistic Regression** is recommended due to its balanced metrics. It offers a good balance between precision and recall, capturing a significant portion of actual defaulters with fewer false positives compared to other models. Logistic Regression is also inherently more interpretable than many complex models like Decision Trees or K-Nearest Neighbors, making it easier to understand the factors influencing loan defaults and make informed decisions. Additionally, Logistic Regression is less likely to overfit the data compared to decision trees, as seen from its moderate accuracy and balanced recall, making it more robust and reliable when applied to new, unseen data. Its computational efficiency and ease of implementation further make Logistic Regression a practical choice for many applications.

In conclusion, while several models were evaluated, Logistic Regression stands out for its balanced performance, interpretability, robustness, and ease of implementation, making it the preferred choice for predicting loan defaults.
"""



import joblib

joblib.dump(lr, 'final_lr_model.pkl')

joblib.dump(scaler, "lr_scaler.pkl")

joblib.dump(col_name, "col_name.pkl")





"""# **MODEL DEPLOYMENT ON FLASK API**

## **CREATING A PREDICTING FUNCTION**
"""

ld.head(1)

lr_model = joblib.load('final_lr_model.pkl')
lr_scaler = joblib.load("lr_scaler.pkl")
col_name  = joblib.load("col_name.pkl")

example = {
    "Age" : 56,
    "Income" : 85994,
    "LoanAmount" : 50587,
    "CreditScore" : 520,
    "MonthsEmployed" : 80,
    "NumCreditLines" : 4,
    "InterestRate" : 15.23,
    "LoanTerm" : 36,
    "DTIRatio" : 0.44,
    "Education" : "Bachelor's",
    "EmploymentType" : "Full-time",
    "MaritalStatus" : "Divorced",
    "HasMortgage"	 : "Yes",
    "HasDependents" : "Yes",
    "LoanPurpose"	: "Other",
    "HasCoSigner" : "Yes"
}

import numpy as np

def return_prediction(model, scaler, col_name, sample_json):
    age = sample_json["Age"]
    income = sample_json["Income"]
    l_amount = sample_json["LoanAmount"]
    cd_score = sample_json["CreditScore"]
    month_emp= sample_json["MonthsEmployed"]
    num_cl = sample_json["NumCreditLines"]
    int_rate = sample_json["InterestRate"]
    loan_term = sample_json["LoanTerm"]
    dti_ratio = sample_json["DTIRatio"]
    edu = sample_json["Education"]
    emp_type = sample_json["EmploymentType"]
    marital_s = sample_json["MaritalStatus"]
    has_mort = sample_json["HasMortgage"]
    has_depd = sample_json["HasDependents"]
    loan_purp = sample_json["LoanPurpose"]
    has_cosg = sample_json["HasCoSigner"]


    cat_df = pd.DataFrame([[edu, emp_type, marital_s, has_mort, has_depd, loan_purp, has_cosg]],
                          columns=['Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner'])

    # One-hot encode categorical features
    cat_encoded = pd.get_dummies(cat_df, drop_first=True)


    num_df = pd.DataFrame([[age, income, l_amount, cd_score, month_emp, num_cl, int_rate, loan_term, dti_ratio]],
                          columns=['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed',
                                   'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio'])
    # Combine numerical and categorical data
    combined_df = pd.concat([num_df, cat_encoded], axis=1)
     # Reindex combined_df to match the training columns, filling missing columns with 0
    combined_df = combined_df.reindex(columns = col_name, fill_value=0)

    # Extract values from combined DataFrame
    loan = combined_df.values

    # Scale numerical features (assumes scaler only expects the numerical part)
    num_scaled = scaler.transform(loan[:, :9])

    # Combine scaled numerical features and categorical features
    loan = np.hstack([num_scaled, loan[:, 9:]])

    prediction = model.predict(loan)

    if prediction == 1:
        return 'Thief! Loan not approved for you'
    else:
        return 'Loan Approved! Don’t let us regret this'

return_prediction(lr_model, lr_scaler,col_name, example)



"""## **CODE FOR DEPLOYMENT**"""

from flask import Flask, request, jsonify
import numpy as np
import joblib
import pandas as pd


def return_prediction(model, scaler, col_name, sample_json):
    age = sample_json["Age"]
    income = sample_json["Income"]
    l_amount = sample_json["LoanAmount"]
    cd_score = sample_json["CreditScore"]
    month_emp= sample_json["MonthsEmployed"]
    num_cl = sample_json["NumCreditLines"]
    int_rate = sample_json["InterestRate"]
    loan_term = sample_json["LoanTerm"]
    dti_ratio = sample_json["DTIRatio"]
    edu = sample_json["Education"]
    emp_type = sample_json["EmploymentType"]
    marital_s = sample_json["MaritalStatus"]
    has_mort = sample_json["HasMortgage"]
    has_depd = sample_json["HasDependents"]
    loan_purp = sample_json["LoanPurpose"]
    has_cosg = sample_json["HasCoSigner"]


    cat_df = pd.DataFrame([[edu, emp_type, marital_s, has_mort, has_depd, loan_purp, has_cosg]],
                          columns=['Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner'])

    # One-hot encode categorical features
    cat_encoded = pd.get_dummies(cat_df, drop_first=True)


    num_df = pd.DataFrame([[age, income, l_amount, cd_score, month_emp, num_cl, int_rate, loan_term, dti_ratio]],
                          columns=['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed',
                                   'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio'])
    # Combine numerical and categorical data
    combined_df = pd.concat([num_df, cat_encoded], axis=1)
     # Reindex combined_df to match the training columns, filling missing columns with 0
    combined_df = combined_df.reindex(columns = col_name, fill_value=0)

    # Extract values from combined DataFrame
    loan = combined_df.values

    # Scale numerical features (assumes scaler only expects the numerical part)
    num_scaled = scaler.transform(loan[:, :9])

    # Combine scaled numerical features and categorical features
    loan = np.hstack([num_scaled, loan[:, 9:]])

    prediction = model.predict(loan)

    if prediction == 1:
        return 'Thief! Loan not approved for you'
    else:
        return 'Loan Approved! Don’t let us regret this'




loan = Flask(__name__)

@loan.route("/")
def index():
    return '<h1>FLASK IS RUNNING</h1>'


lr_model = joblib.load('final_lr_model.pkl')
lr_scaler = joblib.load("lr_scaler.pkl")
col_name  = joblib.load("col_name.pkl")


@loan.route('/loan_predict', methods = ['POST'])
def loan_prediction():
	content = request.json
	results = return_prediction(lr_model, lr_scaler, content)
	return jsonify(results)



if __name__=='__main__':
	loan.run()

